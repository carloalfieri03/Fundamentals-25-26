2025-12-03 17:18:13,721 INFO    MainThread:45316 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-12-03 17:18:13,721 INFO    MainThread:45316 [wandb_setup.py:_flush():80] Configure stats pid to 45316
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_setup.py:_flush():80] Loading settings from /Users/carloalbertoalfieri/.config/wandb/settings
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_setup.py:_flush():80] Loading settings from /Users/carloalbertoalfieri/Desktop/FDS_PROJECT/wandb/settings
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_init.py:setup_run_log_directory():713] Logging user logs to ./wandb/run-20251203_171813-pryxdr7r/logs/debug.log
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to ./wandb/run-20251203_171813-pryxdr7r/logs/debug-internal.log
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_init.py:init():840] calling init triggers
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_init.py:init():845] wandb.init called with sweep_config: {}
config: {'_wandb': {}}
2025-12-03 17:18:13,722 INFO    MainThread:45316 [wandb_init.py:init():888] starting backend
2025-12-03 17:18:13,978 INFO    MainThread:45316 [wandb_init.py:init():891] sending inform_init request
2025-12-03 17:18:13,998 INFO    MainThread:45316 [wandb_init.py:init():899] backend started and connected
2025-12-03 17:18:14,000 INFO    MainThread:45316 [wandb_init.py:init():969] updated telemetry
2025-12-03 17:18:14,020 INFO    MainThread:45316 [wandb_init.py:init():993] communicating run to backend with 90.0 second timeout
2025-12-03 17:18:14,871 INFO    MainThread:45316 [wandb_init.py:init():1040] starting run threads in backend
2025-12-03 17:18:14,911 INFO    MainThread:45316 [wandb_run.py:_console_start():2504] atexit reg
2025-12-03 17:18:14,911 INFO    MainThread:45316 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-12-03 17:18:14,912 INFO    MainThread:45316 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-12-03 17:18:14,912 INFO    MainThread:45316 [wandb_run.py:_redirect():2444] Redirects installed.
2025-12-03 17:18:14,913 INFO    MainThread:45316 [wandb_init.py:init():1080] run started, returning control to user process
2025-12-03 17:18:14,933 INFO    MainThread:45316 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'num_classes': 6, 'embed': {'_target_': 'net.cnn.EncoderWrapper', 'in_channels': 9, 'layer_widths': [64, 128, 256], 'kernel_size': 5, 'stride': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.0001}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': 256, 'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'bidirectional': True}, 'decoder': {'_target_': 'net.cnn.DecoderWrapper', 'in_channels': 256, 'layer_widths': [128, 64, 9], 'kernel_size': 5, 'stride': 2, 'output_padding': 1, 'use_batchnorm': True}}"}
2025-12-03 17:18:51,148 INFO    MainThread:45316 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'num_classes': 6, 'embed': {'_target_': 'net.cnn.EncoderWrapper', 'in_channels': 9, 'layer_widths': [64, 128, 256], 'kernel_size': 5, 'stride': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.0001}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': 256, 'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'bidirectional': True}, 'decoder': {'_target_': 'net.cnn.DecoderWrapper', 'in_channels': 256, 'layer_widths': [128, 64, 9], 'kernel_size': 5, 'stride': 2, 'output_padding': 1, 'use_batchnorm': True}}"}
2025-12-03 17:20:03,933 INFO    MainThread:45316 [wandb_run.py:_config_callback():1385] config_cb None None {'cfg': "{'num_classes': 6, 'embed': {'_target_': 'net.cnn.EncoderWrapper', 'in_channels': 9, 'layer_widths': [64, 128, 256], 'kernel_size': 5, 'stride': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.0001}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': 256, 'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'bidirectional': True}, 'decoder': {'_target_': 'net.cnn.DecoderWrapper', 'in_channels': 256, 'layer_widths': [128, 64, 9], 'kernel_size': 5, 'stride': 2, 'output_padding': 1, 'use_batchnorm': True}}"}
2025-12-03 17:20:07,784 INFO    MainThread:45316 [wandb_run.py:_config_callback():1385] config_cb None None {'seed': 42, 'net': {'num_classes': 6, 'embed': {'_target_': 'net.cnn.EncoderWrapper', 'in_channels': 9, 'layer_widths': [64, 128, 256], 'kernel_size': 5, 'stride': 2}, 'unembed': {'_target_': 'torch.nn.LazyLinear', 'out_features': 6}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.0001}, 'rnn_block': {'_target_': 'net.rnn.LSTMBlock', 'input_size': 256, 'hidden_size': 128, 'num_layers': 2, 'dropout': 0.3, 'bidirectional': True}, 'decoder': {'_target_': 'net.cnn.DecoderWrapper', 'in_channels': 256, 'layer_widths': [128, 64, 9], 'kernel_size': 5, 'stride': 2, 'output_padding': 1, 'use_batchnorm': True}}, 'trainer': {'max_epochs': 100, 'log_every_n_steps': 10}, 'dataset': {'data_dir': '/Users/carloalbertoalfieri/desktop/FDS_PROJECT/data', 'batch_size': 32, 'val_split': 0.2}, 'wandb': {'project': 'FDS_PROJECT', 'entity': 'catairu-sapienza-universit-di-roma', 'name': 'skif2_provaCA'}, 'info': {'num_params': 1000198}}
2025-12-03 17:20:07,785 INFO    wandb-AsyncioManager-main:45316 [service_client.py:_forward_responses():80] Reached EOF.
2025-12-03 17:20:07,786 INFO    wandb-AsyncioManager-main:45316 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
